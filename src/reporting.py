from __future__ import annotations

from pathlib import Path

from .models import AuditReport, Evidence


def render_detective_report(
    repo_url: str,
    pdf_path: str | None,
    evidences: dict[str, Evidence],
    logs: list[str],
    output_path: str,
) -> str:
    lines: list[str] = []
    lines.append("# Interim Detective Audit Report")
    lines.append("")
    lines.append("## Input")
    lines.append("")
    lines.append(f"- Repository Target: `{repo_url}`")
    lines.append(f"- PDF Report: `{pdf_path or 'N/A'}`")
    lines.append("")
    lines.append("## Evidence Index")
    lines.append("")

    for evidence_id in sorted(evidences.keys()):
        ev = evidences[evidence_id]
        lines.append(f"### {evidence_id}")
        lines.append(f"- Goal: {ev.goal}")
        lines.append(f"- Found: `{ev.found}`")
        lines.append(f"- Confidence: `{ev.confidence:.2f}`")
        lines.append(f"- Location: `{ev.location}`")
        lines.append(f"- Rationale: {ev.rationale}")
        if ev.content:
            lines.append("- Content:")
            lines.append("```text")
            lines.append(ev.content)
            lines.append("```")
        if ev.tags:
            lines.append(f"- Tags: {', '.join(ev.tags)}")
        lines.append("")

    lines.append("## Execution Log")
    lines.append("")
    for log in logs:
        lines.append(f"- {log}")

    content = "\n".join(lines) + "\n"
    out = Path(output_path)
    out.parent.mkdir(parents=True, exist_ok=True)
    out.write_text(content, encoding="utf-8")
    return content


def render_audit_report_markdown(report: AuditReport) -> str:
    total = len(report.criterion_breakdown)
    excellent = sum(1 for c in report.criterion_breakdown if c.final_score == 5)
    good = sum(1 for c in report.criterion_breakdown if 3 <= c.final_score <= 4)
    needs_improvement = sum(1 for c in report.criterion_breakdown if c.final_score <= 2)

    lines: list[str] = []
    lines.append(f"# Peer Audit Final Result: {report.repo_target}")
    lines.append("")
    lines.append("## Executive Summary")
    lines.append("")
    lines.append(
        f"Overall Score: {report.aggregate_score:.2f}/5.0. "
        f"Criteria Evaluated: {total}. Excellent (5): {excellent}, "
        f"Good (3-4): {good}, Needs Improvement (1-2): {needs_improvement}. "
        "Ready for staging with minor refinements."
    )
    lines.append("")
    lines.append(f"**Overall Score:** {report.aggregate_score:.2f}/5.0")
    lines.append("")
    lines.append("## Criterion Breakdown")
    lines.append("")

    for criterion in report.criterion_breakdown:
        lines.append(f"### {criterion.criterion_name}")
        lines.append(f"**Final Score:** {criterion.final_score}/5")
        lines.append("")
        lines.append("**Judge Opinions:**")
        lines.append("")

        def _judge_key(judge_name: str) -> int:
            order = {"Defense": 0, "Prosecutor": 1, "TechLead": 2}
            return order.get(judge_name, 99)

        for opinion in sorted(criterion.judge_opinions, key=lambda op: _judge_key(op.judge)):
            cited = ", ".join(opinion.cited_evidence) if opinion.cited_evidence else "none"
            lines.append(f"- **{opinion.judge}** (Score: {opinion.score}): {opinion.argument}")
            lines.append(f"  - Cited: {cited}")
            lines.append("")

        if criterion.final_score >= 4:
            remediation = f"✅ {criterion.criterion_name} meets expectations. Consider documenting best practices for team reference."
        else:
            remediation = criterion.remediation[0] if criterion.remediation else "Address evidence gaps and re-run audit."
        lines.append(f"**Remediation:** {remediation}")
        if criterion.violated_rules:
            lines.append(f"**Deterministic Rules Applied:** {', '.join(criterion.violated_rules)}")
        lines.append("")
        lines.append("---")
        lines.append("")

    lines.append("## Remediation Plan")
    lines.append("")
    lines.append("# Prioritized Remediation Plan")
    lines.append("")
    ranked = sorted(report.criterion_breakdown, key=lambda c: (c.final_score, c.criterion_id))
    for idx, criterion in enumerate(ranked, start=1):
        lines.append(f"## Priority {idx}: {criterion.criterion_name} (Score: {criterion.final_score}/5)")
        if criterion.final_score >= 4:
            lines.append(
                f"✅ **Issue:** ✅ {criterion.criterion_name} meets expectations. "
                "Consider documenting best practices for team reference."
            )
        else:
            top_item = criterion.remediation[0] if criterion.remediation else "Address evidence gaps and re-run audit."
            lines.append(f"⚠️ **Issue:** {top_item}")
        lines.append("")

    lines.append("---")
    lines.append("*Remediation priorities based on: score severity, security impact, and production readiness*")
    lines.append("")
    lines.append("---")
    lines.append("*Report generated by Automaton Auditor Swarm v3.0.0*")
    lines.append(f"*Timestamp: {report.generated_at or 'N/A'}*")
    lines.append(f"*Methodology: {report.methodology}*")

    return "\n".join(lines).rstrip() + "\n"


def write_report(path: str, content: str) -> None:
    out = Path(path)
    out.parent.mkdir(parents=True, exist_ok=True)
    out.write_text(content, encoding="utf-8")
